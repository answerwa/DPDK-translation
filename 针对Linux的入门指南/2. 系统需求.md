# 2. [系统需求](http://dpdk.org/doc/guides/linux_gsg/sys_reqs.html)

本章介绍了编译DPDK需要的软件包。

> **注意**
>
> 如果DPDK在英特尔®通信芯片组89xx系列平台上使用，请参阅*英特尔®通信芯片组89xx系列软件Linux入门指南*。

## 2.1. x86平台BOIOS设定前提

对于大多数平台，使用DPDK的基础功能不需要特殊的BIOS设置。但是，对于额外的HPET定时器和电源管理功能以及40G网卡上的小数据包的高性能，可能需要进行更改BIOS设置。有关所需更改的更多信息，请参阅[启动附加功能](https://github.com/answerwa/DPDK-translation/blob/master/针对Linux的入门指南/5.%20启用附加功能.md)部分。

## 2.2. DPDK的编译

**所需工具：**

> **注意**
>
> 已使用Fedora 18进行过测试。其它系统上所需安装命令和安装包可能有出入。有关其它Linux发行版和已测试版本的详细信息，请参阅DPDK发行说明。

- GNU `make` 。

- coreutils: `cmp`, `sed`, `grep`, `arch` 等。

- gcc: 对于所有平台，建议使用4.9或更高版本。在某些发行版中，会默认启用一些特定的编译器标志和连接器标志，会影响性能（例如 `-fstack-protector` ）。请参阅使用的发行版文档和 `gcc -dumpspecs` 。

- libc头文件，通常打包为`gcc-multilib` （`glibc-devel.i686` / `libc6-dev-i386`；`glibc-devel.x86_64` / `libc6-dev` 适用Intel架构的64位编译； `glibc-devel.ppc64` 使用IBM Power架构的64位编译）。

- 构建内核模块需要的Linux内核头文件和源码。 (kernel - devel.x86_64; kernel - devel.ppc64)

- 在64位系统上进行32位编译所需的其它软件包是：

  - glibc.i686, libgcc.i686, libstdc++.i686 and glibc-devel.i686 for Intel i686/x86_64;
  - glibc.ppc64, libgcc.ppc64, libstdc++.ppc64 and glibc-devel.ppc64 for IBM ppc_64;

  > **注意**
  >
  > x86_x32 ABI目前仅在高于Ubuntu 13.10的发行版和Debian最近的发行版上支持。只支持的编译器是gcc 4.9+。

- Python, version 2.7+ or 3.2+，使用DPDK包中的各种帮助脚本。

**可选工具：**

- Intel® C++ Compiler (icc). 可能需要额外的库用于安装。参考编译器安装文件目录下的icc安装指南。
- IBM® Advance ToolChain for Powerlinux. 这是一组开源开发工具和运行时库，可以让用户在Linux上获得IBM最新的POWER硬件功能的优势。要安装它，请参阅IBM官方安装文档。
- libpcap头文件和库(libpcap-devel)，用来编译和使用libpcap-based poll-mode驱动。此驱动默认禁用，可以在编译时，通过在配置文件中设置`CONFIG_RTE_LIBRTE_PMD_PCAP=y`来启用。
- libarchive头文件和库，在某些单元测试中会被用到，可以通过tar来获取这些资源。

## 2.3. 运行DPDK程序

要运行DPDK程序，可能需要在目标机器上进行某些定制。

### 2.3.1. 系统软件

**需求**

- Kernel version >= 2.6.34

  使用的内核版本可以用此命令查看：

  ```
  uname -r

  ```

- glibc >= 2.7 (cpuset相关功能)

  可以使用 `ldd --version` 检查此版本。

- 内核配置

  在Fedora OS和其它常用发行版中，例如Ubuntu，Red Hat Enterprise Linux，供应商提供的内核配置可用于运行大多数DPDK程序。

  对于其它的内核构建，应为DPDK启用的选项包括：

  - 支持UIO
  - 支持HUGETLBFS
  - 支持PROC_PAGE_MONITOR
  - 如果需要支持HPET，还应启用HPET和HPET_MMAP配置选项。有关更多详细信息，请参阅[高精度事件计时器（HPET）功能](https://github.com/answerwa/DPDK-translation/blob/master/针对Linux的入门指南/5.%20启用附加功能.md#51-高精度事件计时器（HPET）功能)部分。

### 2.3.2. 在Linux环境中使用Hugepages。

用于数据包缓冲区的大内存池分配需要支持Hugepage（必须在运行的内核中启用HUGETLBFS选项，如上一节所述）。通过使用hugepage分配，性能增加，因为需要更少的页面，因此需要更少的Translation Lookaside Buffers（TLBs，高速翻译高速缓存），减少了将虚拟页面地址翻译成物理页面地址所需的时间。没有hugepages，标准4k页面大小会导致高TLB错失率，性能下降。

#### 2.3.2.1. 为DPDK的使用保留Hugepages

hugepages的分配应在启动时或系统启动后尽快进行，以防止内存在物理内存中分段。要在启动时保留hugepages，需要传递一个参数给内核命令行上的Linux内核。

对于2 MB页面，只需将hugepages选项传递给内核。 例如，要保留1024个2 MB的页面，请使用：

```
hugepages=1024

```

对于其它的hugepage大小，例如1G页面，必须明确指定大小，也可以选择将其设置为系统的默认hugepage大小。例如，要以四个1G页面的形式预留4G的hugepage内存，应将以下选项传递给内核：

```
default_hugepagesz=1G hugepagesz=1G hugepages=4
```

> **注意**
>
> CPU支持的主机大小可以从Intel架构的CPU标志中确定。 如果存在pse，则支持2M的hugepages; 如果存在pdpe1gb，则支持1G的hugepages。 在IBM Power架构中，支持的hugepage大小为16MB和16GB。



>**注意**
>
>对于64位应用程序，如果平台支持，建议使用1 GB的hugepages。



在双插槽NUMA系统的情况下，启动时hugepages的保留数量通常在两个插槽之间平均分配（假设两个插槽上都有足够的内存）。

有关这些和其他内核选项的更多详细信息，请参阅Linux源代码树中的Documentation / kernel-parameters.txt文件。

**替代方案：**

对于2 MB页面，还可以在系统启动后分配hugepages。 这是通过回调`/sys/devices/`目录中nr_hugepages文件所需的hugepages数来完成的。 对于单节点系统，使用的命令如下（假设需要1024个页面）：

```
echo 1024 > /sys/kernel/mm/hugepages/hugepages-2048kB/nr_hugepages
```

在NUMA机器上，应该在单独的节点上显式分配页面：

```
echo 1024 > /sys/devices/system/node/node0/hugepages/hugepages-2048kB/nr_hugepages
echo 1024 > /sys/devices/system/node/node1/hugepages/hugepages-2048kB/nr_hugepages

```

> **注意**
>
> 对于1G页面，系统启动后无法保留页面内存。
>
> 在IBM POWER系统上，nr_overcommit_hugepages应该设置为与nr_hugepages相同的值。 例如，如果所需的页码为128，则使用以下命令：
>
>
> ```
> echo 128 > /sys/kernel/mm/hugepages/hugepages-16384kB/nr_hugepages
> echo 128 > /sys/kernel/mm/hugepages/hugepages-16384kB/nr_overcommit_hugepages
> ```
>

#### 2.3.2.2. 在DPDK中使用Hugepages 

一旦保留了hugepage内存，为了使内存可用于DPDK，请执行以下步骤：

```
mkdir /mnt/huge
mount -t hugetlbfs nodev /mnt/huge

```

通过将以下行添加到`/etc/fstab` 文件中，挂载点可以在重新启动之后永久保存：

```
nodev /mnt/huge hugetlbfs defaults 0 0

```

对于1GB页面，页面大小必须指定为挂载选项选项：

```
nodev /mnt/huge_1GB hugetlbfs pagesize=1GB 0 0

```

### 2.3.3. Xen Domain0 Support in the Linux Environment

The existing memory management implementation is based on the Linux kernel hugepage mechanism. On the Xen hypervisor, hugepage support for DomainU (DomU) Guests means that DPDK applications work as normal for guests.

However, Domain0 (Dom0) does not support hugepages. To work around this limitation, a new kernel module rte_dom0_mm is added to facilitate the allocation and mapping of memory via **IOCTL** (allocation) and **MMAP** (mapping).

#### 2.3.3.1. Enabling Xen Dom0 Mode in the DPDK

By default, Xen Dom0 mode is disabled in the DPDK build configuration files. To support Xen Dom0, the CONFIG_RTE_LIBRTE_XEN_DOM0 setting should be changed to “y”, which enables the Xen Dom0 mode at compile time.

Furthermore, the CONFIG_RTE_EAL_ALLOW_INV_SOCKET_ID setting should also be changed to “y” in the case of the wrong socket ID being received.

#### 2.3.3.2. Loading the DPDK rte_dom0_mm Module

To run any DPDK application on Xen Dom0, the `rte_dom0_mm` module must be loaded into the running kernel with rsv_memsize option. The module is found in the kmod sub-directory of the DPDK target directory. This module should be loaded using the insmod command as shown below (assuming that the current directory is the DPDK target directory):

```
sudo insmod kmod/rte_dom0_mm.ko rsv_memsize=X

```

The value X cannot be greater than 4096(MB).

#### 2.3.3.3. Configuring Memory for DPDK Use

After the rte_dom0_mm.ko kernel module has been loaded, the user must configure the memory size for DPDK usage. This is done by echoing the memory size to a memsize file in the /sys/devices/ directory. Use the following command (assuming that 2048 MB is required):

```
echo 2048 > /sys/kernel/mm/dom0-mm/memsize-mB/memsize

```

The user can also check how much memory has already been used:

```
cat /sys/kernel/mm/dom0-mm/memsize-mB/memsize_rsvd

```

Xen Domain0 does not support NUMA configuration, as a result the `--socket-mem` command line option is invalid for Xen Domain0.

Note

The memsize value cannot be greater than the rsv_memsize value.

#### 2.3.3.4. Running the DPDK Application on Xen Domain0

To run the DPDK application on Xen Domain0, an extra command line option `--xen-dom0` is required.
```

```