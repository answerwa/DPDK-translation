# 3. [环境抽象层](http://dpdk.org/doc/guides/prog_guide/env_abstraction_layer.html)

环境抽象层（EAL）负责获取对硬件和内存空间等低级资源的访问。 它提供了一个通用接口，可以隐藏应用程序和库的环境细节。 初始化例程有责任决定如何分配这些资源（即内存空间，PCI设备，计时器，控制台等）。

来自EAL的典型服务包括：

- DPDK 加载和启动：DPDK 及其应用程序作为单个应用程序链接，必须通过某种方式加载。
- 核心关联/分配过程：EAL 提供了将执行单元分配给特定内核以及创建执行实例的机制。
- 系统内存预留：EAL有助于预留不同的内存区域，例如设备交互的物理内存区域。
- PCI地址抽象：EAL提供了访问PCI地址空间的接口。
- 跟踪和调试功能：日志，dump_stack，panic 等。
- 实用程序功能：libc 中未提供的旋转锁和原子计数器。
- CPU 功能标识：在运行时确定是否支持特定功能，例如 Intel®AVX。确定当前CPU是否支持二进制编译的功能集。
- 中断处理：向特定中断源注册/注销回调的接口。
- 报警功能：设置/删除要在特定时间运行的回调的接口。

## 3.1. Linux用户执行环境中的EAL

在 Linux 用户空间环境中，DPDK 应用程序使用 pthread 库作为用户空间应用程序运行。有关设备和地址空间的 PCI 信息通过`/sys`内核接口和内核模块（如 uio_pci_generic 或 igb_uio）发现。请参阅Linux内核中的UIO：用户空间驱动程序文档。 这个内存在应用程序中已映射。

EAL使用 hugetlbfs 中的 mmap() 进行物理内存分配（使用巨页来提高性能）。该内存暴露于DPDK服务层，如[Mempool 库](https://github.com/answerwa/DPDK-translation/blob/master/%E7%A8%8B%E5%BA%8F%E5%91%98%E6%8C%87%E5%8D%97/5.%20%E5%86%85%E5%AD%98%E6%B1%A0%E5%BA%93.md)。

此时，DPDK 服务层将被初始化，然后通过 pthread setaffinity 调用，每个执行单元将分配给一个特定的逻辑内核作为用户级线程运行。

时间参考由 CPU 时间戳计数器（TSC）或 HPET 内核 API 通过 mmap() 调用提供。

### 3.1.1. 初始化和核心启动

初始化的一部分由glibc的启动函数完成。在初始化时也执行检查，以确保 CPU 支持配置文件中选择的微架构类型。然后，main() 函数被调用。 核心初始化和启动在 rte_eal_init() 中完成（参见API文档）。它包括对pthread库的调用（更具体地说是pthread_self()，pthread_create() 和 pthread_setaffinity_np()）。

![](http://dpdk.org/doc/guides/_images/linuxapp_launch.svg)

Fig. 3.1 Linux应用程序环境中的EAL初始化

> **注意**
>
> 作为主核心上的整体应用程序初始化的一部分，应对对象进行初始化，如内存区域，环，内存池，lpm 表和哈希表。这些对象的创建和初始化函数不是多线程安全的。但一旦初始化，对象本身可以安全地同时在多个线程中使用。

### 3.1.2. 支持多进程

Linuxapp EAL 允许多进程以及多线程（pthread）部署模型。 有关详细信息，请参见[支持多进程](https://github.com/answerwa/DPDK-translation/blob/master/程序员指南/20.%20多进程支持.md)章节。

### 3.1.3. 内存映射探索和内存预留

大型连续物理内存的分配是使用 hugetlbfs 内核文件系统完成的。EAL提供了一个API来在这个连续的内存中保留命名的内存区域。该内存区域的保留物理地址也由内存区域预留 API 返回给用户。

> **注意**
>
> 使用 rte_malloc 提供的 API 完成的内存预留也由 hugetlbfs 文件系统的页面支持。

### 3.1.4. 无 hugetbls 支持 Xen Dom0

现有的内存管理实现是基于 Linux 内核的 hugepage 机制。但是，Xen Dom0 不支持 hugepages，因此添加了一个新的 Linux 内核模块 rte_dom0_mm 来解决这个限制。

EAL使用 IOCTL 接口通知 Linux 内核模块 rte_dom0_mm 分配指定大小的内存，并从模块中获取所有内存段信息，EAL 使用 MMAP 接口映射已分配的内存。对于每个内存段，物理地址在其内部是连续的，但实际的硬件地址在 2 MB 内是连续的。

### 3.1.5. PCI 访问

EAL使用内核提供的 `/sys/bus/pci` 实用程序来扫描 PCI 总线上的内容。为了访问 PCI 内存，一个名为 uio_pci_generic 的内核模块提供 `/dev/uioX` 设备文件和 `/sys` 中的资源文件，可以从应用程序中获取对PCI地址空间的访问权限。DPDK 特定的 igb_uio 模块也可以用于此。这两款驱动都使用 uio 内核功能（用户驱动程序）。

### 3.1.6. Per-lcore 和共享变量

> **注意**
>
> lcore是指处理器的逻辑执行单元，有时称为硬件线程。

共享变量是默认行为。 Per-lcore变量使用线程本地存储（TLS）来实现，以提供 per-thread 本地存储。

### 3.1.7. 日志

日志 API 由 EAL 提供。 默认情况下，在 Linux 应用程序中，日志将发送到 syslog，也发送到控制台。 但是，日志功能可以被用户覆盖，以使用不同的日志记录机制。

#### 3.1.7.1. 跟踪和调试功能

在 glibc 中有一些调试函数可以将栈转存。rte_panic() 函数可以自发地引发 SIG_ABORT，它可以触发由gdb读取的core文件的生成。

### 3.1.8. CPU 功能识别

EAL可以在运行时查询CPU（使用 rte_cpu_get_feature() 函数）来确定哪些 CPU 功能可用。

### 3.1.9. 用户空间中断事件

- 主机线程中的用户空间中断和报警处理

EAL 创建一个主机线程来轮询 UIO 设备文件描述符以检测中断。回调可以通过特定中断事件的EAL函数进行注册或取消注册，并以异步方式在主机线程中调用。EAL 还允许以与 NIC 中断相同的方式使用定时回调。

> **注意**
>
> 在 DPDK PMD 中，由专用主机线程处理的唯一中断是链路状态更改（链接建立和链接关闭通知）以及突然的设备移除。

- RX 中断事件

每个 PMD 提供的接收和发送例程不限制自己在轮询线程模式下执行。为了在微小的吞吐量时缓解空闲轮询，暂停轮询并等待直到唤醒事件发生是很有用的。RX 中断是这种唤醒事件的首选，但可能不会是唯一的。

EAL 为事件驱动的线程模式提供事件 API。以 linuxapp 为例，实现依赖于 epoll。每个线程都可以监视一个 epoll 实例，其中添加了所有唤醒事件的文件描述符。事件文件描述符根据 UIO/VFIO 规范创建并映射到中断向量中。从 bsdapp 的角度来看，kqueue 是替代方法，但尚未实现。

EAL 初始化事件文件描述符和中断向量之间的映射，而每个设备初始化中断向量和队列之间的映射。这样，EAL 实际上并不知道特定向量的中断原因。eth_dev 驱动程序负责编写后一个映射。

> **注意**
>
> 每个队列 RX 中断事件只允许在支持多个 MSI-X 向量的 VFIO 中。在 UIO 中，RX 中断与其他中断原因共享相同的向量。在这种情况下，当 RX 中断和 LSC（链路状态改变）中断都被使能（intr_conf.lsc == 1 && intr_conf.rxq == 1）时，只有前者才能生效。

RX 中断由 ethdev API - `rte_eth_dev_rx_intr_ *` 控制/启用/禁用 。如果 PMD 尚未支持，则返回失败。`intr_conf.rxq` 标志用于打开每个设备的RX中断功能。

- 设备移除事件

该事件由在总线级别被移除的设备触发。其底层资源可能不可用（即未映射的 PCI 映射）。PMD 必须确保在这种情况下，应用程序仍然可以安全地使用其回调。

此事件可以以与订阅链接状态更改事件相同的方式订阅。执行上下文因此是相同的，即它是专用的中断主机线程。

考虑到这一点，应用程序很可能想要关闭已经发出设备删除事件的设备。在这种情况下，调用 `rte_eth_dev_close()` 可以触发它取消注册自己的设备删除事件回调。必须注意不要从中断处理程序上下文关闭设备。有必要重新安排这种关闭操作。

### 3.1.10. 黑名单

EAL PCI 设备黑名单功能可用于将某些 NIC 端口标记为黑名单，因此它们将被 DPDK 忽略。要被加入黑名单的端口使用PCIe *描述符（域：总线：设备.函数）进行识别。

### 3.1.11. 杂项功能

锁和原子操作是根据架构（i686 和 x86_64）决定。

## 3.2. 内存段和内存区（memzone）

物理内存映射由 EAL 中的此功能提供。由于物理内存可能有间隙，所以在描述符表中描述了存储器，每个描述符（称为 rte_memseg）描述了存储器的连续部分。

此外，memzone 分配器的作用是保留物理内存的连续部分。当保留内存时，这些区域由唯一的名称标识。

rte_memzone 描述符也位于配置结构中。使用 rte_eal_get_configuration() 访问此结构。内存区域的查找（按名称）返回包含内存区域的物理地址的描述符。

通过提供align参数（默认情况下，它们与缓存行大小对齐），可以通过特定的起始地址对齐来保留内存区域。对齐值应为 2 的幂，且不小于高速缓存行大小（64 字节）。内存区域也可以从 2 MB 或 1 GB 的hugepages保留，只要系统上都可用。

## 3.3. 多 pthread

DPDK通常为每个内核指定一个 pthread，以避免任务切换的开销。这样可以显着提升性能，但缺乏灵活性，且并不总是有效。

电源管理通过限制 CPU 运行时频率来帮助提高 CPU 效率。但是，也可以利用可用的空闲周期来利用 CPU 的全部功能。

通过利用 cgroup，可以简单地分配 CPU 利用率配额。这提供了另一种提高 CPU 效率的方法，但有一个先决条件;DPDK必须处理每个核心的多个 pthread 之间的上下文切换。

为了进一步的灵活性，将 pthread 关系不仅设置为 CPU 而且设置为 CPU 集是非常有用的。

### 3.3.1. EAL pthread 和 lcore 亲和力

术语 “lcore” 是指一个 EAL 线程，它是一个真正的 Linux/FreeBSD pthread。“EAL pthreads” 由EAL创建和管理，并执行 *remote_launch* 发出的任务。在每个 EAL pthread 中，有一个称为 *_lcore_id* 的 TLS（线程本地存储），用于唯一标识。由于 EAL pthreads 通常将物理 CPU 绑定为1：1，所以 *_lcore_id* 通常等于 CPU ID。

但是，当使用多个 pthread 时，EAL pthread 和指定的物理 CPU 之间的绑定不再总是为1：1。 EAL pthread 可能与 CPU 集相关，因此 *_lcore_id* 将不同于 CPU ID。因此，有一个 EAL长 选项 '-lcores' 定义为分配 CPU 的亲和力的 lcores。对于指定的 lcore ID 或 ID 组，该选项允许设置该 EAL pthread 的 CPU 集。

- 格式模式：

  –lcores=’\<lcore_set>\[@cpu_set][,[@cpu_set],...]’

'lcore_set' 和 'cpu_set' 可以是单个数字，范围或组。

数字是“digit([0-9]+)”; 范围是“\<number>-\<number>”; 组是“(\<number|range> [,\<number|range>,...])”。

如果未提供'@cpu_set'值，'cpu_set'的值将默认为'lcore_set'值。

```sh
For example, "--lcores='1,2@(5-7),(3-5)@(0,2),(0,6),7-8'" which means start 9 EAL thread;
    lcore 0 runs on cpuset 0x41 (cpu 0,6);
    lcore 1 runs on cpuset 0x2 (cpu 1);
    lcore 2 runs on cpuset 0xe0 (cpu 5,6,7);
    lcore 3,4,5 runs on cpuset 0x5 (cpu 0,2);
    lcore 6 runs on cpuset 0x41 (cpu 0,6);
    lcore 7 runs on cpuset 0x80 (cpu 7);
    lcore 8 runs on cpuset 0x100 (cpu 8).
```

使用此选项，对于每个给定的 lcore ID，可以分配相关联的 CPU。

### 3.3.2. 非 EAL pthread 支持

可以使用任何用户pthread（也称为非EAL pthreads）的DPDK执行上下文。在非EAL pthread中，*_lcore_id* 始终是 LCORE_ID_ANY，标识它不是具有唯一有效的 *_lcore_id* 的EAL线程。一些库将使用可选择的唯一 ID（例如 TID），有些库将不会受到影响，有些库会生效，但会受到限制（例如定时器和 mempool 库）。

所有这些影响都在[已知问题](https://github.com/answerwa/DPDK-translation/blob/master/程序员指南/3.%20环境抽象层.md#334-已知问题)部分提及。

### 3.3.3. 公共线程 API

为线程引入了两个公共 API `rte_thread_set_affinity()` 和 `rte_pthread_get_affinity()`。当它们在任何 pthread 上下文中使用时，线程本地存储（TLS）将被设置/获取。

那些TLS包括 *_cpuset* 和 *_socket_id*：

- *_cpuset* 存储 pthread 与其相关联的 CPU 位图。
- *_socket_id* 存储 CPU 集的 NUMA 节点。 如果 CPU 集中的 CPU 属于不同的 NUMA 节点，则 *_socket_id* 将被设置为 SOCKET_ID_ANY。

### 3.3.4. 已知问题

- rte_mempool

  rte_mempool 在 mempool 中使用 per-lcore 缓存。对于非 EAL pthreads，`rte_lcore_id()` 不会返回有效的数字。所以现在，当 rte_mempool 与非 EAL pthreads 一起使用时，put/get 操作将绕过默认的mempool缓存，并且由于这个旁路而导致性能损失。只有结合接受显式高速缓存参数的 `rte_mempool_generic_put()` 和 `rte_mempool_generic_get()` 可以在非 EAL 上下文中使用用户拥有的外部缓存。

- rte_ring

  rte_ring 支持多生成者入队和多消费者出队。然而，这是非抢占式的，这将造成 rte_mempool 无法抢占的影响。

  > **注意**
  >
  > “非抢先”约束意味着：
  >
  >    - 在给定的环上执行多生产者入队的 pthread 不能被另一个在同一个环上执行多生成者排队的 pthread 抢占。
  >
  >    - 在给定的环上执行多消费者出队的 pthread 不能被另一个在同一个环上执行多消费者出队的 pthread 抢占。  
  >
  > 绕过此约束可能导致第二个 pthread 旋转，直到第一个 pthread 再次被调度。此外，如果第一个 pthread 被优先级较高的上下文抢占，甚至可能会导致死锁。
  >

  这并不意味着它不能被使用，简单地说，当同一个核心上的多线程被使用时，需要缩小这种情况。

  1. 它可以用于任何单一生产者或单一消费者的情况。
  2. 它可以由调度策略为 SCHED_OTHER（cfs）的多生产者/消费者 pthread 使用。 使用前，用户应注意性能损失。
  3. 调度策略是 SCHED_FIFO 或 SCHED_RR 的多生产者/消费者 pthread 不得使用它。

- rte_timer

  不允许在非 EAL pthread 上运行 `rte_timer_manager()`。 但是，允许从非 EAL pthread 重置/停止定时器。

- rte_log

  在非 EAL pthreads 中，没有每个线程的 loglevel 和 logtype，使用全局日志级别。

- misc

  非 EAL pthread 不支持 rte_ring，rte_mempool 和 rte_timer 的调试统计信息。

### 3.3.5. cgroup 控件

以下是 cgroup 控件使用的简单示例，在同一个核心（$ CPU）上执行数据包 I/O 有两个 pthread（t0 和 t1）。 我们期待只有 50％ 的 CPU 支出在数据包 IO 上。

```sh
mkdir /sys/fs/cgroup/cpu/pkt_io
mkdir /sys/fs/cgroup/cpuset/pkt_io

echo $cpu > /sys/fs/cgroup/cpuset/cpuset.cpus

echo $t0 > /sys/fs/cgroup/cpu/pkt_io/tasks
echo $t0 > /sys/fs/cgroup/cpuset/pkt_io/tasks

echo $t1 > /sys/fs/cgroup/cpu/pkt_io/tasks
echo $t1 > /sys/fs/cgroup/cpuset/pkt_io/tasks

cd /sys/fs/cgroup/cpu/pkt_io
echo 100000 > pkt_io/cpu.cfs_period_us
echo  50000 > pkt_io/cpu.cfs_quota_us
```

## 3.4. Malloc

EAL 提供了一个 malloc API 来分配任何大小的内存。

该 API 的目的是提供类似 malloc 的函数，以允许从 hugepage 内存分配并促进应用程序移植。DPDK API 参考手册介绍了可用的函数。

通常，这些类型的分配不应该在数据平面处理中进行，因为它们比基于池的分配慢，并且在分配和自由路径中使用锁。但是，它们可以在配置代码中使用。

有关详细信息，请参阅 *DPDK API 参考手册*中的 rte_malloc() 函数说明。

### 3.4.1. Cookies

当启用 CONFIG_RTE_MALLOC_DEBUG 时，分配的内存包含覆盖保护字段，以帮助识别缓冲区溢出。

### 3.4.2. 对齐和 NUMA 限制

rte_malloc() 获取一个对齐参数，该参数可用于请求在该值的倍数上对齐的内存区域（必须是 2 的幂）。

在支持 NUMA 的系统上，对 rte_malloc() 函数的调用将返回在进行调用的核心的 NUMA 套接字上分配的内存。还提供了一组 API，以便在 NUMA 插槽上直接分配内存，或者通过分配给另一个核心所在的 NUMA 插槽上的内存，在这种情况下，除了分配内存，内存是由一个逻辑核心使用。

### 3.4.3. 用例

该 API 旨在由初始化时需要类似 malloc 的函数的应用程序使用。为了在运行时分配/释放数据，在应用程序的快速路径中，应该使用内存池库。

### 3.4.4. Internal Implementation

#### 3.4.4.1. Data Structures

There are two data structure types used internally in the malloc library:

- struct malloc_heap - used to track free space on a per-socket basis
- struct malloc_elem - the basic element of allocation and free-space tracking inside the library.

##### 3.4.4.1.1. Structure: malloc_heap

The malloc_heap structure is used to manage free space on a per-socket basis. Internally, there is one heap structure per NUMA node, which allows us to allocate memory to a thread based on the NUMA node on which this thread runs. While this does not guarantee that the memory will be used on that NUMA node, it is no worse than a scheme where the memory is always allocated on a fixed or random node.

The key fields of the heap structure and their function are described below (see also diagram above):

- lock - the lock field is needed to synchronize access to the heap. Given that the free space in the heap is tracked using a linked list, we need a lock to prevent two threads manipulating the list at the same time.
- free_head - this points to the first element in the list of free nodes for this malloc heap.

Note

The malloc_heap structure does not keep track of in-use blocks of memory, since these are never touched except when they are to be freed again - at which point the pointer to the block is an input to the free() function.

Fig. 3.2 Example of a malloc heap and malloc elements within the malloc library

##### 3.4.4.1.2. Structure: malloc_elem

The malloc_elem structure is used as a generic header structure for various blocks of memory. It is used in three different ways - all shown in the diagram above:

1. As a header on a block of free or allocated memory - normal case
2. As a padding header inside a block of memory
3. As an end-of-memseg marker

The most important fields in the structure and how they are used are described below.

Note

If the usage of a particular field in one of the above three usages is not described, the field can be assumed to have an undefined value in that situation, for example, for padding headers only the “state” and “pad” fields have valid values.

- heap - this pointer is a reference back to the heap structure from which this block was allocated. It is used for normal memory blocks when they are being freed, to add the newly-freed block to the heap’s free-list.
- prev - this pointer points to the header element/block in the memseg immediately behind the current one. When freeing a block, this pointer is used to reference the previous block to check if that block is also free. If so, then the two free blocks are merged to form a single larger block.
- next_free - this pointer is used to chain the free-list of unallocated memory blocks together. It is only used in normal memory blocks; on `malloc()` to find a suitable free block to allocate and on `free()` to add the newly freed element to the free-list.
- state - This field can have one of three values: `FREE`, `BUSY` or `PAD`. The former two are to indicate the allocation state of a normal memory block and the latter is to indicate that the element structure is a dummy structure at the end of the start-of-block padding, i.e. where the start of the data within a block is not at the start of the block itself, due to alignment constraints. In that case, the pad header is used to locate the actual malloc element header for the block. For the end-of-memseg structure, this is always a `BUSY` value, which ensures that no element, on being freed, searches beyond the end of the memseg for other blocks to merge with into a larger free area.
- pad - this holds the length of the padding present at the start of the block. In the case of a normal block header, it is added to the address of the end of the header to give the address of the start of the data area, i.e. the value passed back to the application on a malloc. Within a dummy header inside the padding, this same value is stored, and is subtracted from the address of the dummy header to yield the address of the actual block header.
- size - the size of the data block, including the header itself. For end-of-memseg structures, this size is given as zero, though it is never actually checked. For normal blocks which are being freed, this size value is used in place of a “next” pointer to identify the location of the next block of memory that in the case of being `FREE`, the two free blocks can be merged into one.

#### 3.4.4.2. Memory Allocation

On EAL initialization, all memsegs are setup as part of the malloc heap. This setup involves placing a dummy structure at the end with `BUSY` state, which may contain a sentinel value if `CONFIG_RTE_MALLOC_DEBUG` is enabled, and a proper [element header](http://dpdk.org/doc/guides/prog_guide/env_abstraction_layer.html#malloc-elem) with `FREE` at the start for each memseg. The `FREE` element is then added to the `free_list` for the malloc heap.

When an application makes a call to a malloc-like function, the malloc function will first index the `lcore_config` structure for the calling thread, and determine the NUMA node of that thread. The NUMA node is used to index the array of `malloc_heap` structures which is passed as a parameter to the `heap_alloc()` function, along with the requested size, type, alignment and boundary parameters.

The `heap_alloc()` function will scan the free_list of the heap, and attempt to find a free block suitable for storing data of the requested size, with the requested alignment and boundary constraints.

When a suitable free element has been identified, the pointer to be returned to the user is calculated. The cache-line of memory immediately preceding this pointer is filled with a struct malloc_elem header. Because of alignment and boundary constraints, there could be free space at the start and/or end of the element, resulting in the following behavior:

1. Check for trailing space. If the trailing space is big enough, i.e. > 128 bytes, then the free element is split. If it is not, then we just ignore it (wasted space).
2. Check for space at the start of the element. If the space at the start is small, i.e. <=128 bytes, then a pad header is used, and the remaining space is wasted. If, however, the remaining space is greater, then the free element is split.

The advantage of allocating the memory from the end of the existing element is that no adjustment of the free list needs to take place - the existing element on the free list just has its size pointer adjusted, and the following element has its “prev” pointer redirected to the newly created element.

#### 3.4.4.3. Freeing Memory

To free an area of memory, the pointer to the start of the data area is passed to the free function. The size of the `malloc_elem` structure is subtracted from this pointer to get the element header for the block. If this header is of type `PAD` then the pad length is further subtracted from the pointer to get the proper element header for the entire block.

From this element header, we get pointers to the heap from which the block was allocated and to where it must be freed, as well as the pointer to the previous element, and via the size field, we can calculate the pointer to the next element. These next and previous elements are then checked to see if they are also `FREE`, and if so, they are merged with the current element. This means that we can never have two `FREE` memory blocks adjacent to one another, as they are always merged into a single block.